{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbec3847",
   "metadata": {},
   "source": [
    "#### Here is a Python script to train and evaluate a single-layer neural network on the MNIST dataset using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcea032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s 23us/sample - loss: 0.7556 - accuracy: 0.8134 - val_loss: 0.4095 - val_accuracy: 0.8980\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3906 - accuracy: 0.8961 - val_loss: 0.3350 - val_accuracy: 0.9085\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 19us/sample - loss: 0.3389 - accuracy: 0.9070 - val_loss: 0.3083 - val_accuracy: 0.9168\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3153 - accuracy: 0.9134 - val_loss: 0.2956 - val_accuracy: 0.9182\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.3009 - accuracy: 0.9165 - val_loss: 0.2843 - val_accuracy: 0.9220\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2911 - accuracy: 0.9193 - val_loss: 0.2793 - val_accuracy: 0.9217\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2839 - accuracy: 0.9210 - val_loss: 0.2756 - val_accuracy: 0.9227\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 18us/sample - loss: 0.2786 - accuracy: 0.9218 - val_loss: 0.2714 - val_accuracy: 0.9260\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2741 - accuracy: 0.9229 - val_loss: 0.2683 - val_accuracy: 0.9258\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.2701 - accuracy: 0.9241 - val_loss: 0.2673 - val_accuracy: 0.9269\n",
      "Test accuracy: 0.9249\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28)).astype('float32') / 255\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, activation='softmax', input_shape=(28 * 28,)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c6360",
   "metadata": {},
   "source": [
    "####  Automate the process of generating the C code with the trained weights and biases using a Python script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9075209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C code has been generated and saved to 'mnist_inference.c'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming the weights and biases from the trained Keras model\n",
    "weights = model.layers[0].get_weights()[0]  # Extract weights\n",
    "biases = model.layers[0].get_weights()[1]   # Extract biases\n",
    "\n",
    "# Flatten the weights matrix in the correct order\n",
    "weights_flattened = weights.flatten()\n",
    "\n",
    "# Generate C code for weights and biases\n",
    "def generate_c_code(weights, biases):\n",
    "    c_code = f\"\"\"\n",
    "#include <math.h>\n",
    "\n",
    "#define INPUT_SIZE {weights.shape[0]}\n",
    "#define OUTPUT_SIZE {weights.shape[1]}\n",
    "\n",
    "float weights[OUTPUT_SIZE][INPUT_SIZE] = {{\n",
    "\"\"\"\n",
    "    for i in range(weights.shape[1]):\n",
    "        c_code += \"    {\"\n",
    "        c_code += \", \".join([f\"{weights[j, i]:.6f}\" for j in range(weights.shape[0])])\n",
    "        c_code += \"},\\n\"\n",
    "    c_code += \"};\\n\\n\"\n",
    "\n",
    "    c_code += \"float biases[OUTPUT_SIZE] = {\"\n",
    "    c_code += \", \".join([f\"{bias:.6f}\" for bias in biases])\n",
    "    c_code += \"};\\n\\n\"\n",
    "\n",
    "    c_code += \"\"\"\n",
    "void predict(float input[INPUT_SIZE], float output[OUTPUT_SIZE]) {\n",
    "    for (int i = 0; i < OUTPUT_SIZE; i++) {\n",
    "        output[i] = biases[i];\n",
    "        for (int j = 0; j < INPUT_SIZE; j++) {\n",
    "            output[i] += input[j] * weights[i][j];\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "    return c_code\n",
    "\n",
    "# Generate the C code\n",
    "c_code = generate_c_code(weights, biases)\n",
    "\n",
    "# Save the generated C code to a file\n",
    "with open(\"mnist_inference.c\", \"w\") as file:\n",
    "    file.write(c_code)\n",
    "\n",
    "print(\"C code has been generated and saved to 'mnist_inference.c'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe58a1e9",
   "metadata": {},
   "source": [
    "#### To validate the accuracy of the generated mnist_inference.c against the MNIST test dataset, we write a Python script that generates another C code. This C code will load the MNIST test dataset, feed each image into the mnist_inference.c functions, and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a673fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test C code has been generated and saved to 'mnist_test.c'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST test dataset\n",
    "(_, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Flatten and normalize the test images\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28)).astype('float32') / 255.0\n",
    "\n",
    "def generate_test_c_code(x_test, y_test):\n",
    "    c_code = \"\"\"\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"mnist_inference.c\"\n",
    "\n",
    "#define NUM_TESTS 10000\n",
    "\n",
    "float test_inputs[NUM_TESTS][INPUT_SIZE] = {\n",
    "\"\"\"\n",
    "    # Add test inputs to the C code\n",
    "    for i in range(x_test.shape[0]):\n",
    "        c_code += \"    {\"\n",
    "        c_code += \", \".join([f\"{x_test[i, j]:.6f}\" for j in range(x_test.shape[1])])\n",
    "        c_code += \"},\\n\"\n",
    "    c_code += \"};\\n\\n\"\n",
    "\n",
    "    # Add test labels to the C code\n",
    "    c_code += \"int test_labels[NUM_TESTS] = {\\n    \"\n",
    "    c_code += \", \".join([str(label) for label in y_test])\n",
    "    c_code += \"\\n};\\n\\n\"\n",
    "\n",
    "    # Add accuracy calculation code\n",
    "    c_code += \"\"\"\n",
    "int main() {\n",
    "    int correct_predictions = 0;\n",
    "    float output[OUTPUT_SIZE];\n",
    "\n",
    "    for (int i = 0; i < NUM_TESTS; i++) {\n",
    "        // Perform prediction\n",
    "        predict(test_inputs[i], output);\n",
    "\n",
    "        // Find the index of the maximum output (predicted class)\n",
    "        int predicted_label = 0;\n",
    "        float max_value = output[0];\n",
    "        for (int j = 1; j < OUTPUT_SIZE; j++) {\n",
    "            if (output[j] > max_value) {\n",
    "                max_value = output[j];\n",
    "                predicted_label = j;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Check if the prediction is correct\n",
    "        if (predicted_label == test_labels[i]) {\n",
    "            correct_predictions++;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Calculate and print accuracy\n",
    "    float accuracy = (float)correct_predictions / NUM_TESTS * 100.0;\n",
    "    printf(\"Accuracy: %f%%\\\\n\", accuracy);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "    return c_code\n",
    "\n",
    "# Generate the test C code\n",
    "test_c_code = generate_test_c_code(x_test, y_test)\n",
    "\n",
    "# Save the generated test C code to a file\n",
    "with open(\"mnist_test.c\", \"w\") as file:\n",
    "    file.write(test_c_code)\n",
    "\n",
    "print(\"Test C code has been generated and saved to 'mnist_test.c'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d2e80",
   "metadata": {},
   "source": [
    "#### Write Python Code to Generate params.c: This Python script will generate the params.c file with hardcoded weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f76cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights/bias has been saved to 'params.c'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace this with your actual weights and biases\n",
    "weights = np.random.randn(10, 784).tolist()  # Example weights\n",
    "biases = np.random.randn(10).tolist()        # Example biases\n",
    "\n",
    "# Write weights to params.c\n",
    "with open('params.c', 'w') as file:\n",
    "    file.write('#include <stdint.h>\\n\\n')\n",
    "    \n",
    "    # Write weights\n",
    "    file.write('const float weights[10][784] = {\\n')\n",
    "    for i in range(10):\n",
    "        file.write('    {')\n",
    "        file.write(', '.join(f'{w:.6f}' for w in weights[i]))\n",
    "        file.write('},\\n')\n",
    "    file.write('};\\n\\n')\n",
    "    \n",
    "    # Write biases\n",
    "    file.write('const float biases[10] = {\\n')\n",
    "    file.write(', '.join(f'{b:.6f}' for b in biases))\n",
    "    file.write('};\\n')\n",
    "\n",
    "print(\"Weights/bias has been saved to 'params.c'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e42c69",
   "metadata": {},
   "source": [
    "####  Compile and Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2780586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcc mnist_test.c -o mnist_test -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf94d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.489998%\r\n"
     ]
    }
   ],
   "source": [
    "!./mnist_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e2448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
